{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using transfer learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 61ms/step - accuracy: 0.1359 - loss: 2.2758 - val_accuracy: 0.1933 - val_loss: 2.1826\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 42ms/step - accuracy: 0.1996 - loss: 2.1691 - val_accuracy: 0.2121 - val_loss: 2.1337\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 42ms/step - accuracy: 0.2113 - loss: 2.1304 - val_accuracy: 0.2199 - val_loss: 2.1134\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 56ms/step - accuracy: 0.2130 - loss: 2.1167 - val_accuracy: 0.2238 - val_loss: 2.1033\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 56ms/step - accuracy: 0.2207 - loss: 2.1059 - val_accuracy: 0.2270 - val_loss: 2.0967\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 49ms/step - accuracy: 0.2255 - loss: 2.1008 - val_accuracy: 0.2236 - val_loss: 2.0923\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.2246 - loss: 2.0988 - val_accuracy: 0.2281 - val_loss: 2.0890\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 38ms/step - accuracy: 0.2259 - loss: 2.0939 - val_accuracy: 0.2275 - val_loss: 2.0859\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 40ms/step - accuracy: 0.2286 - loss: 2.0895 - val_accuracy: 0.2321 - val_loss: 2.0831\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.2313 - loss: 2.0873 - val_accuracy: 0.2309 - val_loss: 2.0813\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 149ms/step - accuracy: 0.1745 - loss: 2.1560 - val_accuracy: 0.1072 - val_loss: 2.3651\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 159ms/step - accuracy: 0.1576 - loss: 2.1839 - val_accuracy: 0.1036 - val_loss: 2.7998\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 198ms/step - accuracy: 0.2111 - loss: 1.9593 - val_accuracy: 0.1177 - val_loss: 2.9317\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 209ms/step - accuracy: 0.2235 - loss: 1.9593 - val_accuracy: 0.1281 - val_loss: 2.9872\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 157ms/step - accuracy: 0.2373 - loss: 1.9165 - val_accuracy: 0.1473 - val_loss: 2.9153\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# One-hot encode the labels correctly\n",
    "train_labels = to_categorical(train_labels, num_classes=10)  # Ensure 10 classes for CIFAR-10\n",
    "test_labels = to_categorical(test_labels, num_classes=10)    # Ensure 10 classes for CIFAR-10\n",
    "\n",
    "# Load the MobileNetV2 model pre-trained on ImageNet, excluding the top (classification) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze the base model's layers to prevent them from being trained\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a new model with the base model followed by custom layers for CIFAR-10 classification\n",
    "model = models.Sequential([\n",
    "    # Step 1: Base model (pre-trained MobileNetV2)\n",
    "    base_model,\n",
    "\n",
    "    # Step 2: Flatten the output of the base model\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # Step 3: Fully connected layer\n",
    "    layers.Dense(64, activation='softmax'),\n",
    "\n",
    "    # Step 4: Output layer (for 10 classes in CIFAR-10)\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#train the model\n",
    "history = model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels))\n",
    "\n",
    "# Unfreeze the base model and fine-tune the entire model (optional, for improved accuracy)\n",
    "# You can fine-tune a few layers of MobileNetV2 by unfreezing them\n",
    "base_model.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate for fine-tuning #learning rate adject any\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),  # Lower learning rate for fine-tuning\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "history_fine = model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
